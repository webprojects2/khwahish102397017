{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMRY+Jn7wFyZqBpPlZdRbi8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import files\n","\n","# Upload the file from your local machine\n","uploaded = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"FrzJX9ynJ2_A","executionInfo":{"status":"ok","timestamp":1729784348353,"user_tz":-330,"elapsed":34721,"user":{"displayName":"DEEKSHA AGGARWAL","userId":"06867900404139755722"}},"outputId":"733f9b89-3e3a-4989-f23c-f2c32179b1ae"},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-c2d909bf-e93c-4a99-9e0e-d50017115c03\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-c2d909bf-e93c-4a99-9e0e-d50017115c03\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Hitters.csv to Hitters.csv\n"]}]},{"cell_type":"markdown","source":["Ques 1"],"metadata":{"id":"EbNAXV8rJ58B"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.model_selection import train_test_split\n","\n","# Step 1: Generate a synthetic dataset\n","np.random.seed(42)\n","\n","# Generate 1000 samples\n","n_samples = 1000\n","\n","# Create 7 correlated features\n","x1 = np.random.rand(n_samples)\n","x2 = x1 + np.random.normal(0, 0.01, n_samples)  # Correlated with x1\n","x3 = x1 + np.random.normal(0, 0.01, n_samples)  # Correlated with x1\n","x4 = x1 + np.random.normal(0, 0.01, n_samples)  # Correlated with x1\n","x5 = x2 + np.random.normal(0, 0.01, n_samples)  # Correlated with x2\n","x6 = x3 + np.random.normal(0, 0.01, n_samples)  # Correlated with x3\n","x7 = x4 + np.random.normal(0, 0.01, n_samples)  # Correlated with x4\n","\n","# Create a target variable with some noise\n","y = 3 * x1 + 2 * x2 + 1.5 * x3 + 0.5 * x4 + np.random.normal(0, 0.1, n_samples)\n","\n","# Combine features into a DataFrame\n","X = pd.DataFrame({\n","    'x1': x1,\n","    'x2': x2,\n","    'x3': x3,\n","    'x4': x4,\n","    'x5': x5,\n","    'x6': x6,\n","    'x7': x7,\n","})\n","\n","# Introduce some NaN values for demonstration (optional)\n","# X.iloc[::50, 0] = np.nan  # Uncomment to introduce NaNs for testing\n","# y[::50] = np.nan  # Uncomment to introduce NaNs for testing\n","\n","# Check for NaN values\n","if X.isnull().values.any() or np.isnan(y).any():\n","    print(\"NaN values detected. Dropping rows with NaNs...\")\n","    # Drop rows with NaN values\n","    X.dropna(inplace=True)\n","    y = y[~X.index].values  # Align target variable after dropping rows\n","\n","# Step 2: Implement Ridge Regression using Gradient Descent\n","def ridge_regression(X, y, learning_rate, regularization_param, n_iterations=1000):\n","    m = len(y)\n","    y = y.reshape(-1, 1)\n","    X_b = np.c_[np.ones((m, 1)), X]  # Add bias term (intercept)\n","\n","    theta = np.random.randn(X_b.shape[1], 1)  # Random initialization of theta\n","    cost_history = []\n","\n","    for iteration in range(n_iterations):\n","        gradients = (2/m) * X_b.T.dot(X_b.dot(theta) - y) + 2 * regularization_param * theta\n","        theta -= learning_rate * gradients\n","        cost = (1/m) * np.sum((X_b.dot(theta) - y)**2) + regularization_param * np.sum(theta[1:]**2)\n","        cost_history.append(cost)\n","\n","    return theta, cost_history\n","\n","# Step 3: Evaluate the model with different hyperparameters\n","learning_rates = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n","regularization_params = [10**-15, 10**-10, 10**-5, 10**-3, 0, 1, 10, 20]\n","\n","best_r2_score = -np.inf\n","best_params = {}\n","\n","# Split the dataset into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","for lr in learning_rates:\n","    for reg_param in regularization_params:\n","        theta, _ = ridge_regression(X_train.values, y_train, learning_rate=lr, regularization_param=reg_param)\n","\n","        # Make predictions\n","        X_test_b = np.c_[np.ones((X_test.shape[0], 1)), X_test]  # Add bias term\n","        y_pred = X_test_b.dot(theta)\n","\n","        # Check for NaN values in predictions\n","        if not np.isnan(y_pred).any() and not np.isnan(y_test).any():\n","            # Compute R² score\n","            r2 = r2_score(y_test, y_pred)\n","\n","            # Print the parameters and the corresponding R² score\n","            print(f'Learning Rate: {lr}, Regularization: {reg_param}, R² Score: {r2:.4f}')\n","\n","            # Check if we have a new best\n","            if r2 > best_r2_score:\n","                best_r2_score = r2\n","                best_params = {'learning_rate': lr, 'regularization_param': reg_param}\n","        else:\n","            print(f\"NaN detected in predictions for LR: {lr}, Reg: {reg_param}\")\n","\n","print(f\"\\nBest Parameters: {best_params}, Best R² Score: {best_r2_score:.4f}\")\n"],"metadata":{"id":"O3liqchcML0Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ques 2"],"metadata":{"id":"_QdliXnvK8OG"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.impute import SimpleImputer\n","\n","# Step 1: Load the dataset\n","df = pd.read_csv('Hitters.csv')\n","print(df)\n","\n","df.info()\n","# (a) Handle null values\n","# Create a mode imputer for categorical columns\n","mode_imputer = SimpleImputer(strategy='most_frequent')\n","\n","# Apply mode imputer to all columns and create a new DataFrame\n","df = pd.DataFrame(mode_imputer.fit_transform(df), columns=df.columns)\n","\n","\n","# Convert categorical columns to numerical using one-hot encoding\n","print(df.Division.unique())\n","print(df.League.unique())\n","print(df.NewLeague.unique())\n","\n","\n","# using label encoding\n","\n","# E = 1 ; W = 0\n","df['Division'].replace(\"E\", 1, inplace = True)\n","df['Division'].replace(\"W\", 0, inplace = True)\n","\n","# A = 1 ; N = 0\n","df['League'].replace(\"A\", 1, inplace = True)\n","df['League'].replace(\"N\", 0, inplace = True)\n","df['NewLeague'].replace(\"A\", 1, inplace = True)\n","df['NewLeague'].replace(\"N\", 0, inplace = True)\n","\n","print(df)\n","\n","# Step 3: Separate input and output features\n","Y = df['Salary']\n","X = df.drop('Salary', axis=1)\n","\n","\n","\n","# Step 4: Scale the input features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Step 5: Train-test split (only perform it once)\n","X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.3, random_state=42)\n","\n","# Step 6: Linear regression using LSE method\n","A = X_train.T.dot(X_train)\n","B = np.linalg.inv(A)\n","C = B.dot(X_train.T)\n","beta = C.dot(Y_train)\n","\n","# Predicting values on test set\n","Y_predict = X_test.dot(beta)\n","\n","# Performance evaluation for Linear Regression\n","error = Y_test - Y_predict\n","sum_square_error = np.sum(np.power(error, 2))\n","mean_square_error = sum_square_error / len(Y_predict)\n","rms_error = np.sqrt(mean_square_error)\n","r2 = 1 - sum_square_error / np.sum((Y_test - np.mean(Y_test)) ** 2)\n","\n","print(f\"Linear Regression MSE: {mean_square_error}\")\n","print(f\"Linear Regression RMSE: {rms_error}\")\n","print(f\"Linear Regression R²: {r2}\")\n","\n","# Ridge regression\n","lamda = 0.5748\n","A_ridge = X_train.T.dot(X_train)\n","I_ridge = np.identity(A_ridge.shape[0])\n","B_ridge = np.linalg.inv(np.add(A_ridge, lamda * I_ridge))\n","C_ridge = B_ridge.dot(X_train.T)\n","beta_ridge = C_ridge.dot(Y_train)\n","\n","# Predicting values on test set for Ridge\n","Y_predict_ridge = X_test.dot(beta_ridge)\n","\n","# Performance evaluation for Ridge Regression\n","error_ridge = Y_test - Y_predict_ridge\n","sum_square_error_ridge = np.sum(np.power(error_ridge, 2))\n","mean_square_error_ridge = sum_square_error_ridge / len(Y_predict_ridge)\n","rms_error_ridge = np.sqrt(mean_square_error_ridge)\n","r2_ridge = 1 - sum_square_error_ridge / np.sum((Y_test - np.mean(Y_test)) ** 2)\n","\n","print(f\"Ridge Regression MSE: {mean_square_error_ridge}\")\n","print(f\"Ridge Regression RMSE: {rms_error_ridge}\")\n","print(f\"Ridge Regression R²: {r2_ridge}\")\n","\n","# Lasso regression\n","lasso_regression = Lasso(alpha=0.5478)\n","lasso_regression.fit(X_train, Y_train)\n","Y_predict_lasso = lasso_regression.predict(X_test)\n","\n","# Performance evaluation for Lasso Regression\n","error_lasso = Y_test - Y_predict_lasso\n","sum_square_error_lasso = np.sum(np.power(error_lasso, 2))\n","mean_square_error_lasso = sum_square_error_lasso / len(Y_predict_lasso)\n","rms_error_lasso = np.sqrt(mean_square_error_lasso)\n","r2_lasso = 1 - sum_square_error_lasso / np.sum((Y_test - np.mean(Y_test)) ** 2)\n","\n","print(f\"Lasso Regression MSE: {mean_square_error_lasso}\")\n","print(f\"Lasso Regression RMSE: {rms_error_lasso}\")\n","print(f\"Lasso Regression R²: {r2_lasso}\")\n"],"metadata":{"id":"m0tjYpF8bQzO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ques 3"],"metadata":{"id":"8hKAenCIeAnH"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.datasets import fetch_california_housing\n","from sklearn.linear_model import RidgeCV, LassoCV\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# Load the California housing dataset\n","data = fetch_california_housing()\n","X = pd.DataFrame(data.data, columns=data.feature_names)\n","y = pd.Series(data.target)\n","\n","# Step 1: Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Step 2: Scale the input features\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Step 3: RidgeCV with Cross-Validation\n","ridge_cv = RidgeCV(alphas=[0.1, 1.0, 10.0], cv=5)  # Cross-validate on 5 folds\n","ridge_cv.fit(X_train_scaled, y_train)\n","\n","# Predictions and evaluation for RidgeCV\n","y_pred_ridge = ridge_cv.predict(X_test_scaled)\n","print(\"RidgeCV Best Alpha:\", ridge_cv.alpha_)\n","print(\"RidgeCV R² Score:\", r2_score(y_test, y_pred_ridge))\n","print(\"RidgeCV RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_ridge)))\n","\n","# Step 4: LassoCV with Cross-Validation\n","lasso_cv = LassoCV(alphas=[0.1, 1.0, 10.0], cv=5)  # Cross-validate on 5 folds\n","lasso_cv.fit(X_train_scaled, y_train)\n","\n","# Predictions and evaluation for LassoCV\n","y_pred_lasso = lasso_cv.predict(X_test_scaled)\n","print(\"LassoCV Best Alpha:\", lasso_cv.alpha_)\n","print(\"LassoCV R² Score:\", r2_score(y_test, y_pred_lasso))\n","print(\"LassoCV RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_lasso)))\n"],"metadata":{"id":"Zar5y9zCeCEB"},"execution_count":null,"outputs":[]}]}